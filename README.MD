
# Deep Learning From Scratch

Program a multilayer perceptron from scratch using built-in Python functions and Numpy.


## Roadmap

- Modeling: Create each component of the multilayer perceptron: layers(input, hidden, output), activation layer, and loss functions.

- Training and Testing: Train and test MLP on both regression and classification problems

- Evaluation: For the classification problem, the MLP achieved an accuracy of 88.69% on the MNIST dataset using cross entropy loss. For the regression problem, the MLP successfully solved the XOR using MSE as the error function.
## Nerual Network Components

- Layer(input, hidden, output): Each layer contains weights and bias as instance variables and forward and back propagation functions

- Activation layer: Applies a specified activation on a layer (forward and back propagation)

- Loss functions: MSE for regression problems and cross entropy for classification problems
## Performance and Visuals

![Visual](https://i.postimg.cc/xC8vTz3p/Screen-Shot-2022-10-23-at-2-38-01-AM.png)

![Visual](https://i.postimg.cc/Y04ZKTW0/Screen-Shot-2022-10-23-at-1-26-11-AM.png)

![Visual](https://i.postimg.cc/RFj5FM9K/Screen-Shot-2022-10-23-at-1-26-39-AM.png)
